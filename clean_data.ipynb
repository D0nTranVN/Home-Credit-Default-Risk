{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "################################################\n",
    "#                   FUNCTION                   #\n",
    "################################################\n",
    "\n",
    "################## CHECK DATA ##################\n",
    "na_train = set()\n",
    "def check_na(df,na_set):\n",
    "    na_set.clear()\n",
    "    for col_name in df:\n",
    "        xna = len(df[df[col_name] == 'XNA'])\n",
    "        na = df[col_name].isnull().sum()\n",
    "        amt = df['SK_ID_CURR'].count()\n",
    "        missing = xna + na\n",
    "        if missing > 0:\n",
    "            print('\\n%s:  %d - %1.2f%% \\n' %(col_name, missing, missing/amt),end='-'*40)\n",
    "            if missing/amt >= 0.3:\n",
    "                na_set.add(col_name + '*')\n",
    "            else: na_set.add(col_name)\n",
    "\n",
    "\n",
    "################## ADJUST ##################\n",
    "#  Delete object which has missing values in some features\n",
    "def na_filter_row(col,df):\n",
    "    amt_mis_1 = df[col].isnull().sum() + len(df[df[col] == 'XNA'])\n",
    "    print('\\n Before deal: %s have %d missing values' %( col, amt_mis_1) )\n",
    "    print('Processing...')\n",
    "    df_notna = df.drop(df.loc[df[col].isnull()].index)\n",
    "    df_notmissing = df_notna.drop(df_notna.loc[df_notna[col]=='XNA'].index)\n",
    "    amt_mis_2 = len(df_notmissing[df_notmissing[col] == 'XNA']) + df_notmissing[col].isnull().sum()\n",
    "    print('After deal: %s have %d missing values \\n' %(col, amt_mis_2 ), end='-'*60 )\n",
    "    return df_notmissing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CODE_GENDER:  4 - 0.00% \n",
      "----------------------------------------\n",
      "AMT_ANNUITY:  12 - 0.00% \n",
      "----------------------------------------\n",
      "AMT_GOODS_PRICE:  278 - 0.00% \n",
      "----------------------------------------\n",
      "NAME_TYPE_SUITE:  1292 - 0.00% \n",
      "----------------------------------------\n",
      "OWN_CAR_AGE:  202929 - 0.66% \n",
      "----------------------------------------\n",
      "OCCUPATION_TYPE:  96391 - 0.31% \n",
      "----------------------------------------\n",
      "CNT_FAM_MEMBERS:  2 - 0.00% \n",
      "----------------------------------------\n",
      "ORGANIZATION_TYPE:  55374 - 0.18% \n",
      "----------------------------------------\n",
      "EXT_SOURCE_1:  173378 - 0.56% \n",
      "----------------------------------------\n",
      "EXT_SOURCE_2:  660 - 0.00% \n",
      "----------------------------------------\n",
      "EXT_SOURCE_3:  60965 - 0.20% \n",
      "----------------------------------------\n",
      "APARTMENTS_AVG:  156061 - 0.51% \n",
      "----------------------------------------\n",
      "BASEMENTAREA_AVG:  179943 - 0.59% \n",
      "----------------------------------------\n",
      "YEARS_BEGINEXPLUATATION_AVG:  150007 - 0.49% \n",
      "----------------------------------------\n",
      "YEARS_BUILD_AVG:  204488 - 0.66% \n",
      "----------------------------------------\n",
      "COMMONAREA_AVG:  214865 - 0.70% \n",
      "----------------------------------------\n",
      "ELEVATORS_AVG:  163891 - 0.53% \n",
      "----------------------------------------\n",
      "ENTRANCES_AVG:  154828 - 0.50% \n",
      "----------------------------------------\n",
      "FLOORSMAX_AVG:  153020 - 0.50% \n",
      "----------------------------------------\n",
      "FLOORSMIN_AVG:  208642 - 0.68% \n",
      "----------------------------------------\n",
      "LANDAREA_AVG:  182590 - 0.59% \n",
      "----------------------------------------\n",
      "LIVINGAPARTMENTS_AVG:  210199 - 0.68% \n",
      "----------------------------------------\n",
      "LIVINGAREA_AVG:  154350 - 0.50% \n",
      "----------------------------------------\n",
      "NONLIVINGAPARTMENTS_AVG:  213514 - 0.69% \n",
      "----------------------------------------\n",
      "NONLIVINGAREA_AVG:  169682 - 0.55% \n",
      "----------------------------------------\n",
      "APARTMENTS_MODE:  156061 - 0.51% \n",
      "----------------------------------------\n",
      "BASEMENTAREA_MODE:  179943 - 0.59% \n",
      "----------------------------------------\n",
      "YEARS_BEGINEXPLUATATION_MODE:  150007 - 0.49% \n",
      "----------------------------------------\n",
      "YEARS_BUILD_MODE:  204488 - 0.66% \n",
      "----------------------------------------\n",
      "COMMONAREA_MODE:  214865 - 0.70% \n",
      "----------------------------------------\n",
      "ELEVATORS_MODE:  163891 - 0.53% \n",
      "----------------------------------------\n",
      "ENTRANCES_MODE:  154828 - 0.50% \n",
      "----------------------------------------\n",
      "FLOORSMAX_MODE:  153020 - 0.50% \n",
      "----------------------------------------\n",
      "FLOORSMIN_MODE:  208642 - 0.68% \n",
      "----------------------------------------\n",
      "LANDAREA_MODE:  182590 - 0.59% \n",
      "----------------------------------------\n",
      "LIVINGAPARTMENTS_MODE:  210199 - 0.68% \n",
      "----------------------------------------\n",
      "LIVINGAREA_MODE:  154350 - 0.50% \n",
      "----------------------------------------\n",
      "NONLIVINGAPARTMENTS_MODE:  213514 - 0.69% \n",
      "----------------------------------------\n",
      "NONLIVINGAREA_MODE:  169682 - 0.55% \n",
      "----------------------------------------\n",
      "APARTMENTS_MEDI:  156061 - 0.51% \n",
      "----------------------------------------\n",
      "BASEMENTAREA_MEDI:  179943 - 0.59% \n",
      "----------------------------------------\n",
      "YEARS_BEGINEXPLUATATION_MEDI:  150007 - 0.49% \n",
      "----------------------------------------\n",
      "YEARS_BUILD_MEDI:  204488 - 0.66% \n",
      "----------------------------------------\n",
      "COMMONAREA_MEDI:  214865 - 0.70% \n",
      "----------------------------------------\n",
      "ELEVATORS_MEDI:  163891 - 0.53% \n",
      "----------------------------------------\n",
      "ENTRANCES_MEDI:  154828 - 0.50% \n",
      "----------------------------------------\n",
      "FLOORSMAX_MEDI:  153020 - 0.50% \n",
      "----------------------------------------\n",
      "FLOORSMIN_MEDI:  208642 - 0.68% \n",
      "----------------------------------------\n",
      "LANDAREA_MEDI:  182590 - 0.59% \n",
      "----------------------------------------\n",
      "LIVINGAPARTMENTS_MEDI:  210199 - 0.68% \n",
      "----------------------------------------\n",
      "LIVINGAREA_MEDI:  154350 - 0.50% \n",
      "----------------------------------------\n",
      "NONLIVINGAPARTMENTS_MEDI:  213514 - 0.69% \n",
      "----------------------------------------\n",
      "NONLIVINGAREA_MEDI:  169682 - 0.55% \n",
      "----------------------------------------\n",
      "FONDKAPREMONT_MODE:  210295 - 0.68% \n",
      "----------------------------------------\n",
      "HOUSETYPE_MODE:  154297 - 0.50% \n",
      "----------------------------------------\n",
      "TOTALAREA_MODE:  148431 - 0.48% \n",
      "----------------------------------------\n",
      "WALLSMATERIAL_MODE:  156341 - 0.51% \n",
      "----------------------------------------\n",
      "EMERGENCYSTATE_MODE:  145755 - 0.47% \n",
      "----------------------------------------\n",
      "OBS_30_CNT_SOCIAL_CIRCLE:  1021 - 0.00% \n",
      "----------------------------------------\n",
      "DEF_30_CNT_SOCIAL_CIRCLE:  1021 - 0.00% \n",
      "----------------------------------------\n",
      "OBS_60_CNT_SOCIAL_CIRCLE:  1021 - 0.00% \n",
      "----------------------------------------\n",
      "DEF_60_CNT_SOCIAL_CIRCLE:  1021 - 0.00% \n",
      "----------------------------------------\n",
      "DAYS_LAST_PHONE_CHANGE:  1 - 0.00% \n",
      "----------------------------------------\n",
      "AMT_REQ_CREDIT_BUREAU_HOUR:  41519 - 0.14% \n",
      "----------------------------------------\n",
      "AMT_REQ_CREDIT_BUREAU_DAY:  41519 - 0.14% \n",
      "----------------------------------------\n",
      "AMT_REQ_CREDIT_BUREAU_WEEK:  41519 - 0.14% \n",
      "----------------------------------------\n",
      "AMT_REQ_CREDIT_BUREAU_MON:  41519 - 0.14% \n",
      "----------------------------------------\n",
      "AMT_REQ_CREDIT_BUREAU_QRT:  41519 - 0.14% \n",
      "----------------------------------------\n",
      "AMT_REQ_CREDIT_BUREAU_YEAR:  41519 - 0.14% \n",
      "----------------------------------------"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#               DEAL WITH NA-VALUES            #\n",
    "################################################\n",
    "application_train = pd.read_csv('application_train.csv')\n",
    "train_df = application_train.copy()\n",
    "check_na(train_df,na_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CODE_GENDER:  4 - 0.00% \n",
      "----------------------------------------\n",
      "AMT_ANNUITY:  12 - 0.00% \n",
      "----------------------------------------\n",
      "AMT_GOODS_PRICE:  278 - 0.00% \n",
      "----------------------------------------\n",
      "OWN_CAR_AGE:  202929 - 0.66% \n",
      "----------------------------------------\n",
      "OCCUPATION_TYPE:  96391 - 0.31% \n",
      "----------------------------------------\n",
      "CNT_FAM_MEMBERS:  2 - 0.00% \n",
      "----------------------------------------\n",
      "ORGANIZATION_TYPE:  55374 - 0.18% \n",
      "----------------------------------------\n",
      "DAYS_LAST_PHONE_CHANGE:  1 - 0.00% \n",
      "----------------------------------------\n",
      "AMT_REQ_CREDIT_BUREAU_HOUR:  41519 - 0.14% \n",
      "----------------------------------------\n",
      "AMT_REQ_CREDIT_BUREAU_DAY:  41519 - 0.14% \n",
      "----------------------------------------\n",
      "AMT_REQ_CREDIT_BUREAU_WEEK:  41519 - 0.14% \n",
      "----------------------------------------\n",
      "AMT_REQ_CREDIT_BUREAU_MON:  41519 - 0.14% \n",
      "----------------------------------------\n",
      "AMT_REQ_CREDIT_BUREAU_QRT:  41519 - 0.14% \n",
      "----------------------------------------\n",
      "AMT_REQ_CREDIT_BUREAU_YEAR:  41519 - 0.14% \n",
      "----------------------------------------"
     ]
    }
   ],
   "source": [
    "################# Special part #################\n",
    "\n",
    "for i in train_df:\n",
    "    if i.endswith('AVG') or i.endswith('MODE') or i.endswith('MEDI'):\n",
    "        # not raw, we can't handle, we don't know how they are calculated (noise, outlier)\n",
    "        del train_df[i]\n",
    "\n",
    "    elif i.startswith('EXT'):\n",
    "        train_df[i].fillna(0.5,inplace = True) # 0.5 is not bad, but not good\n",
    "\n",
    "    elif i.endswith('CIRCLE'):\n",
    "        del train_df[i] # don't have infor about how to calculate \"social circle\"\n",
    "\n",
    "    elif i in {'NAME_TYPE_SUITE','WEEKDAY_APPR_PROCESS_START','HOUR_APPR_PROCESS_START'}:\n",
    "        del train_df[i] # Feature selection ( delete feature we will not use)\n",
    "\n",
    "check_na(train_df,na_train) # require to check"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Before deal: CODE_GENDER have 4 missing values\n",
      "Processing...\n",
      "After deal: CODE_GENDER have 0 missing values \n",
      "------------------------------------------------------------\n",
      " Before deal: ORGANIZATION_TYPE have 55374 missing values\n",
      "Processing...\n",
      "After deal: ORGANIZATION_TYPE have 0 missing values \n",
      "------------------------------------------------------------\n",
      " Before deal: AMT_REQ_CREDIT_BUREAU_QRT have 33856 missing values\n",
      "Processing...\n",
      "After deal: AMT_REQ_CREDIT_BUREAU_QRT have 0 missing values \n",
      "------------------------------------------------------------\n",
      " Before deal: AMT_ANNUITY have 11 missing values\n",
      "Processing...\n",
      "After deal: AMT_ANNUITY have 0 missing values \n",
      "------------------------------------------------------------\n",
      " Before deal: DAYS_LAST_PHONE_CHANGE have 0 missing values\n",
      "Processing...\n",
      "After deal: DAYS_LAST_PHONE_CHANGE have 0 missing values \n",
      "------------------------------------------------------------\n",
      " Before deal: CNT_FAM_MEMBERS have 1 missing values\n",
      "Processing...\n",
      "After deal: CNT_FAM_MEMBERS have 0 missing values \n",
      "------------------------------------------------------------\n",
      " Before deal: AMT_REQ_CREDIT_BUREAU_HOUR have 0 missing values\n",
      "Processing...\n",
      "After deal: AMT_REQ_CREDIT_BUREAU_HOUR have 0 missing values \n",
      "------------------------------------------------------------\n",
      " Before deal: AMT_REQ_CREDIT_BUREAU_WEEK have 0 missing values\n",
      "Processing...\n",
      "After deal: AMT_REQ_CREDIT_BUREAU_WEEK have 0 missing values \n",
      "------------------------------------------------------------\n",
      " Before deal: AMT_REQ_CREDIT_BUREAU_YEAR have 0 missing values\n",
      "Processing...\n",
      "After deal: AMT_REQ_CREDIT_BUREAU_YEAR have 0 missing values \n",
      "------------------------------------------------------------\n",
      " Before deal: AMT_REQ_CREDIT_BUREAU_DAY have 0 missing values\n",
      "Processing...\n",
      "After deal: AMT_REQ_CREDIT_BUREAU_DAY have 0 missing values \n",
      "------------------------------------------------------------\n",
      " Before deal: AMT_GOODS_PRICE have 216 missing values\n",
      "Processing...\n",
      "After deal: AMT_GOODS_PRICE have 0 missing values \n",
      "------------------------------------------------------------\n",
      " Before deal: AMT_REQ_CREDIT_BUREAU_MON have 0 missing values\n",
      "Processing...\n",
      "After deal: AMT_REQ_CREDIT_BUREAU_MON have 0 missing values \n",
      "------------------------------------------------------------"
     ]
    }
   ],
   "source": [
    "################## Delete Na-observation ##################\n",
    "\n",
    "for col in na_train:\n",
    "    if col.endswith('*'): del train_df[col[:-1]] #  delete feature miss >= 30% data\n",
    "    else: train_df = na_filter_row(col,train_df) # with feature miss < 30%, we delete Na obs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "check_na(train_df,na_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "################## SUM OF SAME FEATURES ##################\n",
    "\n",
    "train_df['SUM_FLAG_DOCUMENT'] = train_df.loc[:, 'FLAG_DOCUMENT_2':'FLAG_DOCUMENT_20'].sum(axis=1)\n",
    "train_df['SUM_AMT_REQ'] = train_df.loc[:, 'AMT_REQ_CREDIT_BUREAU_HOUR':'AMT_REQ_CREDIT_BUREAU_YEAR'].sum(axis=1)\n",
    "# del unnecessary col\n",
    "for i in train_df.columns.tolist():\n",
    "    if i.startswith('FLAG_DOC') or i.startswith('AMT_REQ'): del train_df[i]\n",
    "\n",
    "# Export not null file\n",
    "train_df.to_csv('application_train_notnull.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\ntrain_notnull = pd.read_csv(\\'application_train_notnull.csv\\')\\n################################################\\n#              DEAL WITH OUTLIER              #\\n################################################\\n\\n################## QUANTILE CUTOFF MENTHOD ##################\\n\\ncutoff = 0.99\\ndrop_idx = []\\nfor column, dtype, in zip(train_notnull.columns, train_notnull.dtypes):\\n    if dtype == \"float64\":\\n        drop_idx += list(train_notnull[train_notnull[column]>train_notnull[column].quantile(cutoff)].index)\\n    if dtype == \"int64\" and train_notnull[column].unique().shape[0]>10:\\n        drop_idx += list(train_notnull[train_notnull[column]>train_notnull[column].quantile(cutoff)].index)\\ndrop_idx = list(dict.fromkeys(drop_idx))\\ntrain_notnull.drop(drop_idx, inplace=True)\\n\\n# Range of age in Vietnam from 20-60, so we need to do some adjustment\\ntrain_notnull = train_notnull[train_notnull.DAYS_BIRTH >= (-61*365)]\\n\\n# check the repayment difficulties percent\\nmean_def = train_notnull[\\'TARGET\\'].mean()\\nprint (\"%.2f%% of the loans in the training data have repayment difficulties.\" %(mean_def*100))\\nprint(\\'Training Features shape: \\', train_notnull.shape)\\ntrain_notnull.to_csv(\\'application_train_clean.csv\\', index=False)\\n'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_notnull = pd.read_csv('application_train_notnull.csv')\n",
    "################################################\n",
    "#              DEAL WITH OUTLIER              #\n",
    "################################################\n",
    "\n",
    "################## QUANTILE CUTOFF MENTHOD ##################\n",
    "\n",
    "cutoff = 0.99\n",
    "drop_idx = []\n",
    "for column, dtype, in zip(train_notnull.columns, train_notnull.dtypes):\n",
    "    if dtype == \"float64\":\n",
    "        drop_idx += list(train_notnull[train_notnull[column]>train_notnull[column].quantile(cutoff)].index)\n",
    "    if dtype == \"int64\" and train_notnull[column].unique().shape[0]>10:\n",
    "        drop_idx += list(train_notnull[train_notnull[column]>train_notnull[column].quantile(cutoff)].index)\n",
    "drop_idx = list(dict.fromkeys(drop_idx))\n",
    "train_notnull.drop(drop_idx, inplace=True)\n",
    "\n",
    "# Range of age in Vietnam from 20-60, so we need to do some adjustment\n",
    "train_notnull = train_notnull[train_notnull.DAYS_BIRTH >= (-61*365)]\n",
    "\n",
    "# check the repayment difficulties percent\n",
    "mean_def = train_notnull['TARGET'].mean()\n",
    "print (\"%.2f%% of the loans in the training data have repayment difficulties.\" %(mean_def*100))\n",
    "print('Training Features shape: ', train_notnull.shape)\n",
    "train_notnull.to_csv('application_train_clean.csv', index=False)\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% You have to disable this block to use LOF method\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of column: \n",
      " int64      21\n",
      "float64    12\n",
      "object      9\n",
      "dtype: int64\n",
      "\n",
      " Unique classes in each object column: \n",
      " NAME_CONTRACT_TYPE      2\n",
      "CODE_GENDER             2\n",
      "FLAG_OWN_CAR            2\n",
      "FLAG_OWN_REALTY         2\n",
      "NAME_INCOME_TYPE        7\n",
      "NAME_EDUCATION_TYPE     5\n",
      "NAME_FAMILY_STATUS      5\n",
      "NAME_HOUSING_TYPE       6\n",
      "ORGANIZATION_TYPE      57\n",
      "dtype: int64\n",
      "\n",
      "4 columns were label encoded\n",
      "\n",
      "8.28% of the loans in the training data have repayment difficulties.\n",
      "Training Features shape:  (218049, 94)\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#                   ENCODING                   #\n",
    "################################################\n",
    "\n",
    "#train_df_encd = pd.read_csv('application_train_clean.csv') # disable if use LOF\n",
    "train_df_encd = pd.read_csv('application_train_notnull.csv') # For LOF\n",
    "\n",
    "# Number of each type of column\n",
    "print('Data type of column: \\n', train_df_encd.dtypes.value_counts())\n",
    "# Number of unique classes in each object column\n",
    "print('\\n Unique classes in each object column: \\n',train_df_encd.select_dtypes('object').apply(pd.Series.nunique, axis = 0))\n",
    "\n",
    "# Encoding Categorical Variables\n",
    "le = LabelEncoder()\n",
    "le_count_train = 0\n",
    "\n",
    "for col in train_df_encd:\n",
    "    if train_df_encd[col].dtype == 'object':\n",
    "        if len(list(train_df_encd[col].unique())) <= 2:\n",
    "            le.fit(train_df_encd[col])\n",
    "            train_df_encd[col] = le.transform(train_df_encd[col])\n",
    "            le_count_train += 1\n",
    "print('\\n%d columns were label encoded\\n' %le_count_train)\n",
    "\n",
    "# [ORGANIZATION TYPE] synthesis\n",
    "train_df_encd['ORGANIZATION_TYPE'] = train_df_encd['ORGANIZATION_TYPE'].map(lambda x: x.split(':')[0] )\n",
    "train_df_encd['ORGANIZATION_TYPE'] = train_df_encd['ORGANIZATION_TYPE'].map(lambda x: x.split(' Type')[0] )\n",
    "\n",
    "# One-hot endcoding\n",
    "train_df_encd = pd.get_dummies(train_df_encd)\n",
    "\n",
    "# check the repayment difficulties percent\n",
    "mean_def = train_df_encd['TARGET'].mean()\n",
    "print (\"%.2f%% of the loans in the training data have repayment difficulties.\" %(mean_def*100))\n",
    "print('Training Features shape: ', train_df_encd.shape)\n",
    "train_df_encd.to_csv('application_train_encd.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208228, 92) (208228,) (208228,)\n",
      "8.37% of the loans in the training data have repayment difficulties.\n"
     ]
    }
   ],
   "source": [
    "# Another method to detect outlier ( time: 17')\n",
    "# Nếu dùng pp này thì cần encoding trước và xóa phương pháp loại trên kia đi\n",
    "\n",
    "################## LOCAL OUTLIER FACTOR ##################\n",
    "\n",
    "id = train_df_encd['SK_ID_CURR'].values\n",
    "del train_df_encd['SK_ID_CURR']\n",
    "y = train_df_encd['TARGET'].values\n",
    "del train_df_encd['TARGET']\n",
    "X = train_df_encd.values\n",
    "\n",
    "# identify outliers in the training dataset\n",
    "lof = LocalOutlierFactor()\n",
    "y_pred = lof.fit_predict(X)\n",
    "\n",
    "# select all rows that are not outliers\n",
    "out_id = y_pred != -1\n",
    "X, y, id = X[out_id, :], y[out_id], id[out_id]\n",
    "\n",
    "# summarize the shape of the updated training dataset\n",
    "print(X.shape, y.shape, id.shape)\n",
    "train_df_encd.columns.tolist()\n",
    "train_v2 = pd.DataFrame(X, columns = train_df_encd.columns.tolist())\n",
    "train_v2['TARGET'] = y\n",
    "train_v2['SK_ID_CURR'] = id\n",
    "train_v2 = train_v2[train_v2.DAYS_BIRTH >= (-61*365)]\n",
    "train_v2 = train_v2[train_v2.CNT_CHILDREN <= 3]\n",
    "\n",
    "mean_def = train_v2['TARGET'].mean()\n",
    "print (\"%.2f%% of the loans in the training data have repayment difficulties.\" %(mean_def*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.37% of the loans in the training data have repayment difficulties.\n"
     ]
    }
   ],
   "source": [
    "# check the repayment difficulties percent\n",
    "\n",
    "#mean_def = train_df_encd['TARGET'].mean()   # disable if use LOF\n",
    "mean_def = train_v2['TARGET'].mean()       # For LOF\n",
    "print (\"%.2f%% of the loans in the training data have repayment difficulties.\" %(mean_def*100))\n",
    "\n",
    "#train_df_encd.to_csv('application_train_final_quantile.csv', index=False)    # disable if use LOF\n",
    "train_v2.to_csv('application_train_final_lof.csv', index=False)        # For LOF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}